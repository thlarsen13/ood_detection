{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Prepare the training dataset.\n",
    "batch_size = 64\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = np.reshape(x_train, (-1, 784))\n",
    "x_test = np.reshape(x_test, (-1, 784))\n",
    "\n",
    "# Reserve 10,000 samples for validation.\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "# Prepare the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_calibration_bin_statistics(\n",
    "    num_bins, logits=None, labels_true=None, labels_predicted=None):\n",
    "    \"\"\" Compute binning statistics required for calibration measures.\n",
    "  Args:\n",
    "    num_bins: int, number of probability bins, e.g. 10.\n",
    "    logits: Tensor, (n,nlabels), with logits for n instances and nlabels.\n",
    "    labels_true: Tensor, (n,), with tf.int32 or tf.int64 elements containing\n",
    "      ground truth class labels in the range [0,nlabels].\n",
    "    labels_predicted: Tensor, (n,), with tf.int32 or tf.int64 elements\n",
    "      containing decisions of the predictive system.  If `None`, we will use\n",
    "      the argmax decision using the `logits`.\n",
    "  Returns:\n",
    "    bz: Tensor, shape (2,num_bins), tf.int32, counts of incorrect (row 0) and\n",
    "      correct (row 1) predictions in each of the `num_bins` probability bins.\n",
    "    pmean_observed: Tensor, shape (num_bins,), tf.float32, the mean predictive\n",
    "      probabilities in each probability bin.\n",
    "    \"\"\"\n",
    "    \n",
    "    if labels_predicted is None:\n",
    "    # If no labels are provided, we take the label with the maximum probability\n",
    "    # decision.  This corresponds to the optimal expected minimum loss decision\n",
    "    # under 0/1 loss.\n",
    "        pred_y = tf.argmax(logits, axis=1, output_type=labels_true.dtype)\n",
    "    else:\n",
    "        pred_y = labels_predicted\n",
    "\n",
    "        correct = tf.cast(tf.equal(pred_y, labels_true), tf.int32)\n",
    "\n",
    "        # Collect predicted probabilities of decisions\n",
    "        pred = tf.nn.softmax(logits, axis=1)\n",
    "        prob_y = tf.gather(\n",
    "          pred, pred_y[:, tf.newaxis], batch_dims=1)  # p(pred_y | x)\n",
    "        prob_y = tf.reshape(prob_y, (ps.size(prob_y),))\n",
    "\n",
    "        # Compute b/z histogram statistics:\n",
    "        # bz[0,bin] contains counts of incorrect predictions in the probability bin.\n",
    "        # bz[1,bin] contains counts of correct predictions in the probability bin.\n",
    "        bins = tf.histogram_fixed_width_bins(prob_y, [0.0, 1.0], nbins=num_bins)\n",
    "        event_bin_counts = tf.math.bincount(\n",
    "          correct * num_bins + bins,\n",
    "          minlength=2 * num_bins,\n",
    "          maxlength=2 * num_bins)\n",
    "        event_bin_counts = tf.reshape(event_bin_counts, (2, num_bins))\n",
    "\n",
    "        # Compute mean predicted probability value in each of the `num_bins` bins\n",
    "        pmean_observed = tf.math.unsorted_segment_sum(prob_y, bins, num_bins)\n",
    "        tiny = np.finfo(dtype_util.as_numpy_dtype(logits.dtype)).tiny\n",
    "        pmean_observed = pmean_observed / (\n",
    "          tf.cast(tf.reduce_sum(event_bin_counts, axis=0), logits.dtype) + tiny)\n",
    "\n",
    "    return event_bin_counts, pmean_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeECE(num_bins, logits=None, labels_true=None,\n",
    "                               labels_predicted=None): \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        num_bins: int, number of probability bins, e.g. 10.\n",
    "        logits: Tensor, (n,nlabels), with logits for n instances and nlabels.\n",
    "        labels_true: Tensor, (n,), with tf.int32 or tf.int64 elements containing\n",
    "          ground truth class labels in the range [0,nlabels].\n",
    "        labels_predicted: Tensor, (n,), with tf.int32 or tf.int64 elements\n",
    "          containing decisions of the predictive system.  If `None`, we will use\n",
    "          the argmax decision using the `logits`.\n",
    "    Returns:\n",
    "        ece: Tensor, scalar, tf.float32.\n",
    "    \"\"\"\n",
    "    with tf.name_scope('expected_calibration_error'):\n",
    "        logits = tf.convert_to_tensor(logits)\n",
    "        labels_true = tf.convert_to_tensor(labels_true)\n",
    "        if labels_predicted is not None:\n",
    "            labels_predicted = tf.convert_to_tensor(labels_predicted)\n",
    "\n",
    "        # Compute empirical counts over the events defined by the sets\n",
    "        # {incorrect,correct}x{0,1,..,num_bins-1}, as well as the empirical averages\n",
    "        # of predicted probabilities in each probability bin.\n",
    "        event_bin_counts, pmean_observed = _compute_calibration_bin_statistics(\n",
    "            num_bins, logits=logits, labels_true=labels_true,\n",
    "            labels_predicted=labels_predicted)\n",
    "\n",
    "        # Compute the marginal probability of observing a probability bin.\n",
    "        event_bin_counts = tf.cast(event_bin_counts, tf.float32)\n",
    "        bin_n = tf.reduce_sum(event_bin_counts, axis=0)\n",
    "        pbins = bin_n / tf.reduce_sum(bin_n)  # Compute the marginal bin probability\n",
    "\n",
    "        # Compute the marginal probability of making a correct decision given an\n",
    "        # observed probability bin.\n",
    "        tiny = np.finfo(np.float32).tiny\n",
    "        pcorrect = event_bin_counts[1, :] / (bin_n + tiny)\n",
    "\n",
    "        # Compute the ECE statistic as defined in reference [1].\n",
    "        ece = tf.reduce_sum(pbins * tf.abs(pcorrect - pmean_observed))\n",
    "    return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "Training loss (for one batch) at step 0: 81.7544\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 1.4238\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.8191\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 1.0635\n",
      "Seen so far: 38464 samples\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.4841\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.8723\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.6052\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.9201\n",
      "Seen so far: 38464 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "    # Iterate over the batches of the dataset.\n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "\n",
    "            # Open a GradientTape to record the operations run\n",
    "            # during the forward pass, which enables auto-differentiation.\n",
    "            \n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            logits = model(x_batch_train, training=True)  # Logits for this minibatch\n",
    "\n",
    "            # Compute the loss value for this minibatch.\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "\n",
    "            # Use the gradient tape to automatically retrieve\n",
    "            # the gradients of the trainable variables with respect to the loss.\n",
    "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "            # Run one step of gradient descent by updating\n",
    "            # the value of the variables to minimize the loss.\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "            # Log every 200 batches.\n",
    "            if step % 200 == 0:\n",
    "                print(\n",
    "                    \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                    % (step, float(loss_value))\n",
    "                )\n",
    "                print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
